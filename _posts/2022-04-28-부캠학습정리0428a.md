---
title: "[MRC] Passage Retrieval"
date: 2022-04-28 18:00:00 +0900
categories:
- 네이버 부스트캠프 ai tech 3기
tags:
- 부스트캠프
- boostcamp
- 부캠_학습정리
- 글쓰기
---

# Sparse Embedding

### Passage Retrieval : 질문(쿼리)에 맞는 문서(passage)를 찾는 것.

쿼리(질문)과 passage를 임베딩한 뒤 유사도로 랭킹을 매기고, 유사도가 가장 높은 passage를 선택한다.  
Open Domain Question Answering : Passage Retrieval + MRC(방대한 데이터로부터 질문에 대한 답을 찾는다.)


### Passage Embedding and Sparse Embedding

Passage Embedding Space : passage embedding의 벡터 공간.  
벡터화 된 passage를 이용하여 passage 간 유사도 등을 알고리즘으로 계산할 수 있다.

Sparse Embedding : 문서마다 단어의 단어 유무를 표시한다(대부분 0으로 표기).

1. BoW를 구성하는 방법...n-gram  
  – unigram (1-gram): It was the best of times => It, was, the, best, of, time  
  – bigram (2-gram): It was the best of times => It was, was the, the best, best of, of times  
2. Term value 를 결정하는 방법  
  – Term이 document에 등장하는지 (binary)  
  – Term이 몇번 등장하는지 (term frequency), 등. (e.g. TF-IDF)  
  
  
- Dimension of embedding vector = number of terms  
    – 등장하는 단어가 많아질수록 증가  
    – N-gram의 n이 커질수록 증가
- Term overlap을 정확하게 잡아 내야 할 때 유용.
- 반면, 의미(semantic)가 비슷하지만 다른 단어인 경우 비교가 불가



### TF-IDF : (해당 문서 내)단어의 등장 빈도 + 단어가 제공하는 정보의 양

- TF = raw count / num words
- DF = term t가 등장한 문서의 개수, n = 총 문서의 개수
- IDF(t) = log(n / DF(t))
- TF-IDF(t, d) : TF-IDF for term t in document d = TF(t, d) * IDF(t)

어떤 단어가 대부분의 문서에 등장한다면 TF값이 높아도 IDF가 0에 가까워서 낮은 TF-IDF를 갖게 된다.

### BM25
- TF-IDF의 개념을 바탕으로 문서의 길이까지 고려하여 점수를 측정한다.
- TF값에 한계를 지정해서 일정 범위를 유지하도록 한다.
- 평균적인 문서의 길이보다 더 작은 문서에서 단어가 매칭된 경우 그 문서에 대해 가중치를 부여한다.


<br/>

# [MRC] Passage Retrieval – Dense Embedding

Passage Retrieval은 인코딩 방법에 관한 것이다.

앞서 설명한 Sparse Embedding은 유사성을 고려하지 못한다(0과 1밖에 없기에..?), 그리고 차원이 너무 많은데 이는 compressed format으로 극복 가능하다.

반면에 Dense Embedding은 각 차원이 특정 term에 대응되지 않고, 각 벡터 위치가 곧 의미다.

### Training Dense Encoder

- BERT as Dense Encoder...[CLS] token의 output 사용함.
- Positive Sampling : 정답 Passage의 유사도를 높이는 방향으로 학습한다.
- 다만, 연관되지 않은 question과 passage embedding 거리는 멀어야 하므로(낮은 유사도) negative sampling을 한다. 즉 음수로 학습.
- positive passage에 대한 negative log likelihood(NLL) loss를 사용한다.
- 평가 방법 : Top-K retrieval accuracy를 사용하는데, 이는 retrieve된 k개 passage 중에서 답을 포함하는 passage의 비율을 가리킨다.


