---
title: "[MRC] MRC 개론"
date: 2022-04-25 22:00:00 +0900
categories:
- 네이버 부스트캠프 ai tech 3기
tags:
- 부스트캠프
- boostcamp
- 부캠_학습정리
- 글쓰기
---

# MRC(Machine Reading Comprehension)

### MRC 종류
1. extractive answer datasets 질문에 대한 답이 항상 지문에 존재한다는 걸 가정하고 지문 속에서 찾아낸다.
2. descriptive/narrative answer datasets 답이 지문 내에서 추출한 span이 아니라 질의를 보고 답변을 생성함.
3. multiple-choice datasets 질의에 대한 답을 가능성 있는 걸로 여러 개 제시함.


### MRC 개선 방향
- paraphrasing 된 문장의 동일성을 이해하기
- 지문에서 알 수 없는 질문이라는 걸 알아차리기
- 여러 개의 글을 취합해서 답변을 준비하기

### MRC 평가 방법

- Extractive Answer, Multiple-choice Datasets
    - exact match(accuracy) : prediction과 ground truth가 정확히 일치하는 샘플 비율이라 완전히 같아야 점수를 얻는다.
    - f1 score : 예측한 답과 ground truth 사이의 token overlap을 f1으로 계산

- Descriptive Answer Datasets
    - ROUGE-L : ground truth와 예측한 답 사이의 overlap을 계산
    - BLEU : 예측한 답과 ground truth 사이의 n-gram precision

<br/>

# Extraction-based MRC

질문에 대한 답이 지문 내에 span으로 존재한다.

- PLM + Classifier 구조
- Pre-processing : 
    - WordPiece tokenizer
    - 정답이 지문 안에 있으니 시작 위치와 끝 위치를 예측하도록 학습한다. token classifation.
- Fine-tuning : BERT...linear transformation 통해서 확률 구하기
- post processing : 
    - 불가능한 답 제거
        - end position이 start position보다 앞에 있는 경우
        - 예측한 위치가 지문을 벗어난 경우
        - 답이 max_answer_length보다 긴 경우
    - 최적의 답안 찾기


<br/>

# Generation-based MRC

- seq2seq PLM 구조
- Free-form text 형태
- 정답 위치를 전해줄 필요가 없다.
- Pre-processing : 
    - WordPiece tokenizer
    - 각 위치마다 모델이 아는 단어들 중 하나의 단어 맞추는 classification 문제
- BART의 인코더는 BERT처럼 bi-directional, 디코더는 GPT처럼 uni-directional(autoregressive), BART의 pre-training...텍스트에 노이즈를 주고 원래 텍스트 복구함.
- Post-processing : 
    - Searching: Greedy Search, Exhaustive Search, Beam Search


