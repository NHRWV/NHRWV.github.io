---
title:  "[DL Basic] RNN"
date:   2022-02-13 00:03:00
categories:
- 네이버 부스트캠프 ai tech 3기
tags:
- 부스트캠프
- boostcamp
- 부캠_학습정리
- 글쓰기
---

Recurrent Neural Networks

# sequential model

길이가 언제 끝날지 모르는 연속되는 데이터라서 어렵다. 그래서 몇 개의 입력이 있든지 동작하는 모델을 만들어야 한다. 그래서 다음번 입력이 무엇이 될지 예측하는 모델. ..naive sequence model
과거의 입력을 어디까지 볼 것인가라는 질문...예를 들어 최근 다섯 개까지만 보겠다. autoregressive model
markov model 바로 직전 상황만 보는 것
latent autoregressive model...하나의 과거 정보에 의존하긴 하는데 그게 이전 과거를 요약한 것. hidden state 존재

recurrent neural network.
short-term dependency : 
long-term dependency 과거의 정보를 취합해야 하는데 먼 과거의 일을 고려하기 힘들다.

long short term meomory...lstm 롱텀디펜던시를 잡기 위함
1510 그림 붙이기
previous cell state 현재 시점까지 입력받은 정보를 취합한 것. 밖으로 나가진 않는다.
previous hidden state 밖으로 나가서 다음 번에도 previous hidden state가 된다.
결국 인풋과 아웃풋이 세 개다. 다만 실제로 나가는 건 ouput밖에 없다고

forget gate : 어떤 정보를 버릴지 정함.
input gate : cell state에 어떤 정보를 올릴지 정함 previous hidden state와 현재 input을 잘 섞어서 업데이트
update cell : 새로운 cell state 갱신
output gate : 어떤 값을 밖으로 내보낼지 정한다...next hidden state


gated recurrent unit : 얘는 게이트가 두 개다.(reset gate, update gate)
hidden state가 곧 아웃풋. cell state가 없어
