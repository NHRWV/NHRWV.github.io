---
title:  "[DL Basic] 딥러닝과 최적화"
date:   2022-02-09 01:02:00
categories:
- 네이버 부스트캠프 ai tech 3기
tags:
- 부스트캠프
- boostcamp
- 부캠_학습정리
- 글쓰기
---

# 딥러닝 기본

### 딥러닝

구현 실력이 중요하다

딥러닝의 핵심 요소는 데이터, 모델, loss function, Optimization Algorithm : loss를 최소화할 알고리즘.
하지만 결국 궁극적인 목표는 loss function이 아니라 다양한 테스트 데이터에서 잘 작동하는 모델을 어떻게 학습시킬지이다.
손실 함수는 우리 목표의 근사치...


### Neural Network - Multi Layer Perceptron

#### Neural Network
인간의 뇌 신경망을 모방하려는 시도이다.  
행렬 연산과 비선형 연산을 반복해서 함수를 근사하는 모델이다.

#### Linear Neural Network

예측치와 실제값의 loss를 최소화하는 w와 b를 찾는 게 목표이다.

역전파..loss function을 줄여야 한다. 파라미터가 어느 방향으로 움직였을 때 손실 함수가 줄어드는지 확인하고 파라미터를 바꿔야 한다. 따라서 loss function을 파라미터로 미분해서 역방향으로 추적한다. 
이는 곧 최적화를 의미한다. 손실함수를 w로 편미분하고, 마찬가지로 b로도 편미분하면서 w, b 업데이트.

하지만 단순히 선형 결합만 반복하면 안된다. 선형 변환 와중에 비선형 변환이 필요하다. 따라서 아래와 같은 활성 함수로 비선형 변환을 거친다.
- ReLU
- Sigmoid
- Hyperbolic Tangent
어떤 게 좋을지는 상황마다 달라.

#### Loss Functions

- Regression Task : MSE.
- Classification Task : CE. 여기서 y는 정답인 class만 값 1을 가진 one hot vector. y hat은 logit이다. 결과적으로 그 class에 해당하는 값만(해당하는 차원 값) 키우는데, 다른 값들에 비해서 더 크기만 하면 분류 가능하다.
- Probablistic Task : MLE.

<br/>

# Optimization

